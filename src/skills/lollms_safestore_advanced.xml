<skill id="lollms-safestore-formatting" title="RAG Context Formatting & Citations" description="Guidelines for formatting SafeStore chunks for LollmsClient to ensure accurate source attribution." category="python/integration/formatting">
    <content>
        <![CDATA[
# ðŸ’Ž SOURCE OF TRUTH: RAG Context Formatting Protocol

When injecting `safe_store` results into a `LollmsClient` prompt, use this specific structure to prevent the AI from confusing different sources.

## ðŸ§± The "Chunk Block" Format
Always wrap each chunk in clear visual delimiters:

```text
[SOURCE ID: {idx}]
FILE: {file_path}
METADATA: {json_metadata}
CONTENT: 
{chunk_text}
--------------------------
```

## ðŸ“œ System Instruction Enforcement
Include this instruction in your system prompt to force the AI to use the data correctly:

```text
### CITATION RULES:
1. You have been provided with several context chunks.
2. Every claim you make MUST be followed by a citation in brackets, e.g., [SOURCE 1].
3. If information contradicts your internal knowledge, prioritize the provided context.
4. Do not mention "The provided text states..."; simply answer the question and cite.
```

## ðŸš€ Optimization: Context Re-Ranking
If `top_k` is large, use the LLM to filter results before the final generation:

```python
def filter_chunks(question, chunks):
    # Ask LLM to pick indices of relevant chunks first
    # This reduces noise and saves tokens for the final generation
    pass 
```
]]>
    </content>
</skill>