<skill id="lollms-instantiation">
    <name>Client Setup &amp; Bindings</name>
    <description>Initializing LollmsClient with native LoLLMs server binding.</description>
    <category>python/lollms_client/setup/lollms</category>
    <language>markdown</language>
    <timestamp>1738425600000</timestamp>
    <content>
        <![CDATA[
# LoLLMs Server Binding

The native LoLLMs server binding connects to a running LoLLMS instance.

```python
lc = LollmsClient(
    llm_binding_name="lollms",
    llm_binding_config={
        # â”€â”€â”€ Connection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        "host_address": "http://localhost:9642",  # ðŸ”´ MANDATORY
                                                  #    - LoLLMs server URL
        
        "model_name": "mistral",                   # ðŸ”´ MANDATORY
                                                  #    - Model identifier configured in server
        
        # â”€â”€â”€ Authentication â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        "service_key": "lollms_SOMERANDOMSEQUENCE",  # ðŸŸ¡ CONTEXTUAL
                                                    #    - Required if server auth enabled
                                                    #    - Default servers: often "lollms" or custom
        
        # â”€â”€â”€ Security â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        "verify_ssl_certificate": True,            # ðŸŸ¢ default: True
                                                   #    - Verify TLS certificates
                                                   
        "certificate_file_name": "path/to/cert.pem"  # ðŸŸ¢ Optional
                                                    #    - Custom CA for self-signed certs
    }
)
```

---

## Config Parameter Reference

| Parameter | Tier | Default | Description |
|-----------|------|---------|-------------|
| `host_address` | ðŸ”´ **Mandatory** | â€” | LoLLMs server URL (default port: **9642**) |
| `model_name` | ðŸ”´ **Mandatory** | â€” | Model name as configured in LoLLMs server |
| `service_key` | ðŸŸ¡ **Contextual** | â€” | Authentication key (required if server has `use_service_key: true`) |
| `verify_ssl_certificate` | ðŸŸ¢ Optional | `True` | TLS certificate verification |
| `certificate_file_name` | ðŸŸ¢ Optional | â€” | Path to custom CA certificate file |

## âš ï¸ Common Pitfalls

| Issue | Cause | Solution |
|-------|-------|----------|
| `Connection refused` | Server not running | Start `lollms-webui` or `lollms-core` first |
| `Authentication failed` | Wrong/missing `service_key` | Check server's `use_service_key` and key value |
| `Model not found` | Model not installed server-side | Install via LoLLMs UI or server API first |
| SSL errors | Self-signed cert without override | Set `verify_ssl_certificate=False` or provide cert |
| Port confusion | Using 9624 (llama.cpp) vs 9642 (LoLLMs) | Verify server actual port in logs |

]]>
    </content>
</skill>