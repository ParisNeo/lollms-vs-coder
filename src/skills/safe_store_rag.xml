<skill id="safe-store-rag" title="SafeStore RAG & Hybrid Search" description="Techniques for hybrid semantic/keyword search and pre-processing document chunks." category="python/safe_store/rag">
    <content>
        <![CDATA[
# ðŸ’Ž SOURCE OF TRUTH: safe_store RAG Patterns

## ðŸ§ª Hybrid Query Pattern
Combine semantic (meaning) and keyword (exact match) search for better recall.

```python
def hybrid_query(semantic_store, keyword_store, query_text, alpha=0.7):
    # Retrieve from both
    s_results = semantic_store.query(query_text, top_k=10)
    k_results = keyword_store.query(query_text, top_k=10)
    
    combined = {}
    for r in s_results:
        combined[r['chunk_id']] = {'data': r, 'score': alpha * r['similarity']}
    for r in k_results:
        if r['chunk_id'] in combined:
            combined[r['chunk_id']]['score'] += (1 - alpha) * r['similarity']
        else:
            combined[r['chunk_id']] = {'data': r, 'score': (1 - alpha) * r['similarity']}
    
    # Sort and return
    return sorted(combined.values(), key=lambda x: x['score'], reverse=True)
```

## âš™ï¸ Chunk Pre-processing
Use `chunk_processor` to transform text *before* it is vectorized.

```python
def my_processor(chunk_text, metadata):
    # Example: Prepend topic to guide the vectorizer
    topic = metadata.get("topic", "general")
    return f"[Topic: {topic}] {chunk_text}"

store.add_document("file.txt", metadata={"topic": "Physics"}, chunk_processor=my_processor)
```

## ðŸ“‹ Best Practices
- **Chunk Size**: Use 256-512 for precision; 1024-2048 for context-heavy prose.
- **Code Strategy**: Always use `chunking_strategy="recursive"` for source code.
- **Deduplication**: Use `store.export_point_cloud(output_format='dict')` and DBSCAN to find centroids of duplicate documents.
]]>
    </content>
</skill>